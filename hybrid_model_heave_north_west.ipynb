{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06669bf-24d6-4e3b-87df-aff9015fc454",
   "metadata": {},
   "source": [
    "# Locate possible outliers in Heave, North, and West data in .BVA files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc283e6-664e-476b-977b-4b67e85b2511",
   "metadata": {},
   "source": [
    "### Load required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2974c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of packages (and their functions) used in the modules below\n",
    "using DataFrames: DataFrame, ncol, nrow\n",
    "using Dates: Day, Dates, DateTime, Hour, Microsecond, Minute, Month, Time, unix2datetime, Year\n",
    "using Flux: Adam, Chain, Dense, Flux, mse, params, relu, train!\n",
    "using JLD2: @load \n",
    "using NativeFileDialog: pick_file\n",
    "using Plots:  annotate!, font, hline!, hspan!, plot, Plots, plotly, plot!, scatter!, text, vline!, xlims, ylims, @layout\n",
    "using Printf: @sprintf\n",
    "using Sockets: gethostname\n",
    "using Statistics: mean, median, quantile, std\n",
    "\n",
    "include(\"model_functions.jl\");    # this contains the functions called by the modules below\n",
    "\n",
    "println(\"Now recover the training data from file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481eee05",
   "metadata": {},
   "source": [
    "### Recover earlier separated training data from file (Note: does not include Model data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from the JLD2 file\n",
    "current_path = pwd() * \"\\\\Training_data\"\n",
    "filterlist = \"JLD2\"\n",
    "infil = pick_file(current_path; filterlist)\n",
    "\n",
    "@time begin\n",
    "    \n",
    "    # Load all saved data and labels\n",
    "    @load infil training_data_good training_data_bad training_data_bad\n",
    "    \n",
    "end\n",
    "\n",
    "println(\"\\nTraining Data loaded successfully.\\n\")\n",
    "println(\"Good data contains \",string(size(training_data_good)[2]),\" records\")\n",
    "println(\"Bad  data contains \",string(size(training_data_bad)[2]),\" records\\n\")\n",
    "\n",
    "println(\"\\nNow build the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b21890",
   "metadata": {},
   "source": [
    "### Build the Model using a hybrid approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    min_max_normalize_matrix()\n",
    "\n",
    "==#\n",
    "\n",
    "# Define autoencoder model\n",
    "hybrid_model = Chain(\n",
    "    Dense(4608, 256, relu),\n",
    "    Dense(256, 128, relu),\n",
    "    Dense(128, 32, relu),\n",
    "    Dense(32, 128, relu),\n",
    "    Dense(128, 256, relu),\n",
    "    Dense(256, 4608)\n",
    ")\n",
    "\n",
    "# Concatenate and normalize the training data\n",
    "training_data_combined = hcat(training_data_good, training_data_bad)\n",
    "training_data_normalized = min_max_normalize_matrix(training_data_combined)\n",
    "training_data_float32 = Float32.(training_data_normalized)\n",
    "\n",
    "hostname = gethostname()\n",
    "println(\"The name of the computer is: \", hostname)\n",
    "\n",
    "# computer-specific actions\n",
    "if hostname == \"QUEENSLAND-BASIN\"  \n",
    "    initial_path = \"E:\\\\Card Data\\\\\"\n",
    "    display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")     \n",
    "    println(\"Building hybrid model now - on this computer it takes about 30s\\n\")\n",
    "else   \n",
    "    initial_path = \"F:\\\\Card Data\\\\\"\n",
    "    display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))\n",
    "    println(\"Building hybrid model now - on this computer it takes about 200s\\n\")\n",
    "end    \n",
    "flush(stdout)  \n",
    "    \n",
    "@time begin\n",
    "    \n",
    "    # Train the model\n",
    "    loss(x) = Flux.mse(hybrid_model(x), x)\n",
    "    opt = Adam()\n",
    "    \n",
    "    data = Iterators.repeated((training_data_float32,), 100)\n",
    "    Flux.train!(loss, Flux.params(hybrid_model), data, opt)\n",
    "    println(\"Model training complete.\")\n",
    "\n",
    "end\n",
    "\n",
    "println(\"\\nNow select a .BVA file to check for outliers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254df62a",
   "metadata": {},
   "source": [
    "### Select a .BVA file to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c069a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    get_hex_array()\n",
    "    get_matches()\n",
    "    f23_first_row_check()\n",
    "    get_heave_north_west()\n",
    "\n",
    "==#\n",
    "\n",
    "hostname = gethostname()\n",
    "##println(\"The name of the computer is: \", hostname)\n",
    "\n",
    "if hostname == \"QUEENSLAND-BASIN\"\n",
    "    \n",
    "    display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "    initial_path = \"E:\\\\Card Data\\\\\"\n",
    "    \n",
    "else\n",
    "    \n",
    "    display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))    \n",
    "    initial_path = \"F:\\\\Card Data\\\\\"\n",
    "    \n",
    "end\n",
    "\n",
    "REC_LENGTH = 4608       # Number of WSE's in a Mk4 30-minute record\n",
    "SAMPLE_FREQUENCY = 2.56 # Mk4 sample frequency in Hertz\n",
    "SAMPLE_LENGTH = 1800    # record length in seconds\n",
    "SAMPLE_RATE = Float64(1/SAMPLE_FREQUENCY) # sample spacing in seconds\n",
    "\n",
    "X_data = Matrix{Float32}(undef, 0, 0)\n",
    "#########################################################################################################################\n",
    "##    confidence_interval = 2.576  # corresponds to a 99% confidence interval (for a normal distribution)\n",
    "##    confidence_interval = 3.0    # corresponds to a 99.73% confidence interval (for a normal distribution)    \n",
    "##    confidence_interval = 3.29   # corresponds to a 99.9% confidence interval (for a normal distribution)\n",
    "#########################################################################################################################\n",
    "\n",
    "infil = pick_file(initial_path)\n",
    "\n",
    "f23_df, Data = get_hex_array(infil)\n",
    "\n",
    "if !isempty(f23_df)\n",
    "    \n",
    "    f23_df = get_matches(Data, f23_df)\n",
    "    \n",
    "    # remove those vectors from F23 df that are not located in the Data vector df\n",
    "    f23_df = f23_first_row_check(f23_df)\n",
    "    \n",
    "    X_data, X_date = get_heave_north_west(Data, f23_df);\n",
    "    \n",
    "    # ensure matrix is Float32 (the format required by the model)\n",
    "    X_data_32 = Float32.(X_data)\n",
    "    \n",
    "    println(string(length(X_date)),\" records processed.\\n\")\n",
    "    println(\"\\nNow run hybrid model against this data to check for outliers!\")\n",
    "    flush(stdout)\n",
    "\n",
    "else\n",
    "\n",
    "    println(\"No f23 data to process!\")\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7bdc8b",
   "metadata": {},
   "source": [
    "### Run the hybrid model against data in the selected .BVA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d7c01-7aa9-4aa4-94f4-055496afc85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    detect_outliers()\n",
    "\n",
    "==#\n",
    "\n",
    "@time begin\n",
    "    \n",
    "    # identify possible outliers in Heave, North, and West data\n",
    "    outlier_heave, uncertain_heave, outlier_dates_heave, uncertain_dates_heave, good_thresh_heave, bad_thresh_heave = \n",
    "        detect_outliers(X_data[:,:,1], X_date, training_data_good, training_data_bad, hybrid_model)\n",
    "    outlier_north, uncertain_north, outlier_dates_north, uncertain_dates_north, good_thresh_north, bad_thresh_north = \n",
    "        detect_outliers(X_data[:,:,2], X_date, training_data_good, training_data_bad, hybrid_model)\n",
    "    outlier_west, uncertain_west, outlier_dates_west, uncertain_dates_west, good_thresh_west, bad_thresh_west = \n",
    "        detect_outliers(X_data[:,:,3], X_date, training_data_good, training_data_bad, hybrid_model)\n",
    "    \n",
    "    # Combine and deduplicate dates across components\n",
    "    all_outlier = unique(vcat(outlier_heave, outlier_north, outlier_west))\n",
    "    all_uncertain = unique(vcat(uncertain_heave, uncertain_north, uncertain_west))\n",
    "    \n",
    "    # Combine and deduplicate dates across components\n",
    "    all_outlier_dates = unique(vcat(outlier_dates_heave, outlier_dates_north, outlier_dates_west))\n",
    "    all_uncertain_dates = unique(vcat(uncertain_dates_heave, uncertain_dates_north, uncertain_dates_west));\n",
    "\n",
    "end\n",
    "\n",
    "# Output results\n",
    "println(\"\\nFor \",infil,\"\\n\")\n",
    "if !isempty(all_outlier_dates)\n",
    "    println(string(length(all_outlier_dates)), \" records contain suspected outliers at the following dates:\\n\")\n",
    "    for date in all_outlier_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "    print(\"\\n\")\n",
    "else\n",
    "    println(\"No suspected outliers detected.\\n\")\n",
    "end\n",
    "\n",
    "if !isempty(all_uncertain_dates)\n",
    "    println(string(length(all_uncertain_dates)), \" records contain uncertain data points at the following dates:\\n\")\n",
    "    for date in all_uncertain_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "else\n",
    "    println(\"No uncertain data points detected.\")\n",
    "end\n",
    "\n",
    "println(\"\\nNow run the plot routine to view the suspect records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86832c4",
   "metadata": {},
   "source": [
    "### Plot records with suspect data (as identified by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69caf74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#==\n",
    "Calls:\n",
    "\n",
    "    do_heave_north_west_plots()\n",
    "\n",
    "==#\n",
    "\n",
    "for ii âˆˆ all_outlier\n",
    "\n",
    "    # Initialize variables\n",
    "    start_time = X_date[ii]\n",
    "       \n",
    "    do_heave_north_west_plots(ii, start_time, X_data)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b882316-6daa-41ea-8da9-da10ed3f0af9",
   "metadata": {},
   "source": [
    "### Plot reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e00a70-38c5-424c-92ea-6cdd20d5fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = DateTime(Year(X_date[1]), Month(X_date[1]), Day(X_date[1])) + Day(1)  # next day's 00:00\n",
    "tick_interval = Hour(2)  # or Hour(6), Day(1), etc., depending on desired interval\n",
    "\n",
    "# Generate tick positions and labels\n",
    "ticks = collect(start_date:tick_interval:X_date[end])\n",
    "tick_labels = Dates.format.(ticks, \"dd HH:MM\")  # Adjust format to show days and hours\n",
    "\n",
    "title=\"Hybrid Model reconstruction errors - \"*split(infil,\"\\\\\")[end]\n",
    "\n",
    "# Set plotting limits of Y-axis\n",
    "y_max = 1.05\n",
    "\n",
    "plot( size=(1200,600), dpi=100, title=title, xlims=(start_time,end_time), ylims=(0,y_max), \n",
    "    xticks=(ticks, tick_labels), xrotation=90, xtickfont=font(7), \n",
    "    yticks = false, ylabel=(\"Reconstruction Error\"),\n",
    "    framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "    legend=:bottomleft, leftmargin=8Plots.mm, bottommargin=5Plots.mm,\n",
    "    grid=true, gridlinewidth=0.125, gridstyle=:dot, gridcolor=:grey, gridalpha=0.5)\n",
    "\n",
    "plot!(X_date, inverted_reconstruction_error, lw=:2, lc=:grey, label=\"\")\n",
    "\n",
    "# Plot bands of error type\n",
    "hspan!([bad_threshold, y_max], fillcolor=:red, fillalpha=:0.125, label=\"Outlier area\")\n",
    "hspan!([uncertain_threshold, bad_threshold], fillcolor=:lightgrey, fillalpha=:0.25, label=\"Uncertain area\")\n",
    "hspan!([0, uncertain_threshold], fillcolor=:green, fillalpha=:0.125, label=\"Valid area\")\n",
    "\n",
    "# Plot location of outliers on X-axis\n",
    "vline!(outlier_dates, ls=:dash, lc=:red, lw=:0.5, label=\"Detected Outliers\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "727c1ca0-3cb9-481b-bfdd-23ced92a98a0",
   "metadata": {},
   "source": [
    "# Calculate reconstruction errors for good and bad training data separately\n",
    "errors_good = calc_reconstruction_errors(Float32.(min_max_normalize_matrix(training_data_good)), hybrid_model)\n",
    "errors_bad = calc_reconstruction_errors(Float32.(min_max_normalize_matrix(training_data_bad)), hybrid_model)\n",
    "\n",
    "# Normalize new data\n",
    "mean_train_selected = mean(training_data_good, dims=1)[:, 1:size(X_data)[2]]\n",
    "std_train_selected = std(training_data_good, dims=1)[:, 1:size(X_data)[2]]\n",
    "\n",
    "X_new_normalized = min_max_normalize_matrix(X_data_32)\n",
    "# Make predictions using the trained model\n",
    "\n",
    "predicted_X_data = hybrid_model(X_new_normalized)\n",
    "reconstruction_error = sum((X_new_normalized .- predicted_X_data) .^ 2, dims=1)\n",
    "reconstruction_error_vector = vec(reconstruction_error)    # convert reconstruction_error matrix to vector\n",
    "#==\n",
    "Note: The reconstruction error is the difference between the original data and the reconstructed data. \n",
    "      This error reflects how well the model can replicate the original data. \n",
    "      A low reconstruction error suggests the model has captured the structure of the data well, \n",
    "          while a high reconstruction error suggests that the data is unusual or anomalous.\n",
    "==#\n",
    "\n",
    "# Normalize reconstruction errors to match scaling with good and bad thresholds\n",
    "normalized_reconstruction_error = min_max_normalize_matrix(reconstruction_error_vector)\n",
    "\n",
    "# Weighting errors for bad data\n",
    "bad_weight_factor = 2.0  # Apply more weight to bad data\n",
    "weighted_errors_bad = errors_bad .* bad_weight_factor\n",
    "\n",
    "# Set separate thresholds\n",
    "good_threshold = quantile(errors_good, 0.95)  \n",
    "bad_threshold = quantile(weighted_errors_bad, 0.995)\n",
    "\n",
    "##threshold = mean(normalized_reconstruction_error) + 3 * std(normalized_reconstruction_error)\n",
    "threshold = quantile(normalized_reconstruction_error, 0.995)\n",
    "\n",
    "println(\"Threshold: \", threshold)\n",
    "println(\"Good data threshold: \", good_threshold)\n",
    "println(\"Bad data threshold: \", bad_threshold)\n",
    "\n",
    "inverted_reconstruction_error = 1.0 .- normalized_reconstruction_error\n",
    "\n",
    "# Calculate adaptive thresholds based on median and standard deviation\n",
    "inverted_median = median(inverted_reconstruction_error)\n",
    "inverted_std = std(inverted_reconstruction_error)\n",
    "\n",
    "# Adaptive uncertain and bad thresholds\n",
    "uncertain_threshold = inverted_median + inverted_std\n",
    "bad_threshold = inverted_median + 1.5 * inverted_std\n",
    "\n",
    "# Identify outliers and uncertain points based on adaptive thresholds\n",
    "outliers = findall(inverted_reconstruction_error .> bad_threshold)\n",
    "uncertain_indices = findall(x -> uncertain_threshold < x <= bad_threshold, inverted_reconstruction_error);\n",
    "\n",
    "# Convert indices to dates if necessary\n",
    "outlier_dates = X_date[outliers]\n",
    "uncertain_dates = X_date[uncertain_indices]\n",
    "\n",
    "# Output results\n",
    "if !isempty(outlier_dates)\n",
    "    println(\"Outliers detected at the following dates:\")\n",
    "    for date in outlier_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "else\n",
    "    println(\"No outliers detected.\")\n",
    "end\n",
    "\n",
    "if !isempty(uncertain_dates)\n",
    "    println(\"Uncertain data points detected at the following dates:\")\n",
    "    for date in uncertain_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "else\n",
    "    println(\"No uncertain data points detected.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a770540-c6de-457d-87c8-89a140f0efaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
