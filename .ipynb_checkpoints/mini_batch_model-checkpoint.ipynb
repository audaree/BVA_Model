{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "818781a6-7827-4c5b-949d-673e9419ab49",
   "metadata": {},
   "source": [
    "### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2974c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames: DataFrame, ncol, nrow\n",
    "using Dates: Dates, DateTime, Time, unix2datetime, Hour, Minute, Microsecond\n",
    "using NativeFileDialog: pick_file\n",
    "using Statistics: median, mean, std, quantile\n",
    "using Plots: Plots, plot, plot!, annotate!, hline!, @layout, text, plotly, font, scatter!, hspan!, vspan!\n",
    "using Printf: @sprintf\n",
    "using Flux, Random, Statistics\n",
    "using JLD2\n",
    "using FilePathsBase\n",
    "using Sockets\n",
    "\n",
    "include(\"model_functions.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481eee05",
   "metadata": {},
   "source": [
    "### Recover earlier separated data from file (Note: does not include Model data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and optimizer states from the JLD2 file\n",
    "current_path = pwd() * \"\\\\Training_data\"\n",
    "filterlist = \"JLD2\"\n",
    "infil = pick_file(current_path; filterlist)\n",
    "\n",
    "# Load all saved data and labels\n",
    "##@load infil training_data training_date training_data_good training_date_good training_data_bad training_date_bad training_indicies_good training_indicies_bad training_labels # median_train std_train\n",
    "@load infil training_data_good training_data_bad training_data_bad\n",
    "\n",
    "println(\"Data and labels loaded successfully.\")\n",
    "println(\"Good data contains \",string(size(training_data_good)[2]),\" records\")\n",
    "println(\"Bad  data contains \",string(size(training_data_bad)[2]),\" records\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b21890",
   "metadata": {},
   "source": [
    "### Build the Model using mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function min_max_normalize_matrix(X)\n",
    "####################################\n",
    "    \n",
    "    min_vals = minimum(X, dims=1)  # Compute min for each column\n",
    "    max_vals = maximum(X, dims=1)  # Compute max for each column\n",
    "    \n",
    "    return((X .- min_vals) ./ (max_vals .- min_vals))\n",
    "    \n",
    "end    # min_max_normalize_matrix()\n",
    "\n",
    "\n",
    "# Function to create mini-batches\n",
    "function create_mini_batches(data, batch_size)\n",
    "##############################################\n",
    "    \n",
    "    num_samples = size(data, 2)  # Number of columns in `data` (each column is a record)\n",
    "    shuffle_indices = randperm(num_samples)  # Shuffle indices for randomness\n",
    "    mini_batches = []\n",
    "    \n",
    "    for i in 1:batch_size:num_samples\n",
    "        end_idx = min(i + batch_size - 1, num_samples)\n",
    "        push!(mini_batches, data[:, shuffle_indices[i:end_idx]])\n",
    "    end\n",
    "    \n",
    "    return(mini_batches)\n",
    "    \n",
    "end    # create_mini_batches()\n",
    "\n",
    "\n",
    "# Training function with mini-batches\n",
    "function train_model_with_mini_batches(model, data, loss_fn, opt, num_epochs=10, batch_size=64)\n",
    "###############################################################################################\n",
    "    \n",
    "    for epoch in 1:num_epochs\n",
    "        mini_batches = create_mini_batches(data, batch_size)\n",
    "        for mini_batch in mini_batches\n",
    "            Flux.train!(loss_fn, Flux.params(model), [(mini_batch,)], opt)\n",
    "        end\n",
    "        println(\"Completed epoch $epoch\")\n",
    "    end\n",
    "    \n",
    "end    # train_model_with_mini_batches()\n",
    "\n",
    "####################################################################\n",
    "####################################################################\n",
    "####################################################################\n",
    "\n",
    "# Define mini-batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Define the refined autoencoder model (unchanged)\n",
    "refined_model = Chain(\n",
    "    Dense(4608, 256, relu),\n",
    "    Dense(256, 128, relu),\n",
    "    Dense(128, 64, relu),\n",
    "    Dense(64, 128, relu),\n",
    "    Dense(128, 256, relu),\n",
    "    Dense(256, 4608)\n",
    ")\n",
    "\n",
    "@time begin\n",
    "    \n",
    "    println(\"Building mini-batch model now\\n\")\n",
    "\n",
    "    # Define the loss function\n",
    "    loss(x) = Flux.mse(refined_model(x), x)\n",
    "\n",
    "    # Define the optimizer\n",
    "    opt = Adam()\n",
    "\n",
    "    # Prepare normalized training data (as before)\n",
    "    training_data_combined = hcat(training_data_good, training_data_bad)\n",
    "    training_data_normalized = min_max_normalize_matrix(training_data_combined)\n",
    "    training_data_float32 = Float32.(training_data_normalized)\n",
    "\n",
    "    # Train the model using mini-batches\n",
    "    num_epochs = 10  # Define the number of epochs for training\n",
    "    train_model_with_mini_batches(refined_model, training_data_float32, loss, opt, num_epochs, batch_size)\n",
    "\n",
    "    println(\"\\nTraining complete with mini-batch processing.\")\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254df62a",
   "metadata": {},
   "source": [
    "### Select a .BVA file to check for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c069a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global X_data = Matrix{Float32}(undef, 0, 0)\n",
    "\n",
    "hostname = gethostname()\n",
    "println(\"The name of the computer is: \", hostname)\n",
    "\n",
    "if hostname == \"QUEENSLAND-BASIN\"\n",
    "    \n",
    "    display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "    \n",
    "else\n",
    "    \n",
    "    display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))    \n",
    "    \n",
    "end\n",
    "\n",
    "\n",
    "REC_LENGTH = 4608       # Number of WSE's in a Mk4 30-minute record\n",
    "SAMPLE_FREQUENCY = 2.56 # Mk4 sample frequency in Hertz\n",
    "SAMPLE_LENGTH = 1800    # record length in seconds\n",
    "SAMPLE_RATE = Float64(1/SAMPLE_FREQUENCY) # sample spacing in seconds\n",
    "\n",
    "#########################################################################################################################\n",
    "##    confidence_interval = 2.576  # corresponds to a 99% confidence interval (for a normal distribution)\n",
    "##    confidence_interval = 3.0    # corresponds to a 99.73% confidence interval (for a normal distribution)    \n",
    "##    confidence_interval = 3.29   # corresponds to a 99.9% confidence interval (for a normal distribution)\n",
    "#########################################################################################################################\n",
    "\n",
    "# Widen screen for better viewing\n",
    "display(HTML(\"<style>.jp-Cell { width: 120% !important; }</style>\"))\n",
    "display(\"text/html\", \"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "if hostname == \"QUEENSLAND-BASIN\"\n",
    "    \n",
    "    initial_path = \"E:\\\\Card Data\\\\\"\n",
    "    \n",
    "else\n",
    "    \n",
    "    initial_path = \"F:\\\\Card Data\\\\\"\n",
    "    \n",
    "end\n",
    "\n",
    "infil = pick_file(initial_path)\n",
    "\n",
    "f23_df, Data = get_hex_array(infil)\n",
    "\n",
    "f23_df = get_matches(Data, f23_df)\n",
    "\n",
    "# remove those vectors from F23 df that are not located in the Data vector df\n",
    "f23_df = f23_first_row_check(f23_df)\n",
    "\n",
    "X_data, X_date = get_heave(Data, f23_df);\n",
    "\n",
    "X_data = Float32.(X_data)\n",
    "\n",
    "println(string(length(X_date)),\" records processed.\\n\")\n",
    "println(\"\\nNow run hybrid model against this data to check for outliers!\")\n",
    "flush(stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7bdc8b",
   "metadata": {},
   "source": [
    "### Run the mini-batches model against data in the selected .BVA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9583d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_reconstruction_errors(data_matrix, model)\n",
    "#######################################################\n",
    "    \n",
    "    reconstruction_errors = Float32[]\n",
    "    \n",
    "    for record in eachcol(data_matrix)\n",
    "        reconstructed_record = model(record)\n",
    "        error = mean((reconstructed_record .- record).^2)\n",
    "        push!(reconstruction_errors, error)\n",
    "    end\n",
    "    \n",
    "    return(reconstruction_errors)\n",
    "    \n",
    "end    # calc_reconstruction_errors()\n",
    "\n",
    "\n",
    "errors_good = calc_reconstruction_errors(Float32.(min_max_normalize_matrix(training_data_good)), refined_model)\n",
    "errors_bad = calc_reconstruction_errors(Float32.(min_max_normalize_matrix(training_data_bad)), refined_model)\n",
    "\n",
    "# Weighting errors for bad data\n",
    "##bad_weight_factor = 3.0  # Apply more weight to bad data\n",
    "##weighted_errors_bad = errors_bad .* bad_weight_factor\n",
    "\n",
    "# Set separate thresholds\n",
    "good_threshold = quantile(errors_good, 0.95)  \n",
    "bad_threshold = quantile(weighted_errors_bad, 0.995)\n",
    "\n",
    "##threshold = mean(normalized_reconstruction_error) + 3 * std(normalized_reconstruction_error)\n",
    "threshold = quantile(normalized_reconstruction_error, 0.995)\n",
    "\n",
    "println(\"Threshold: \", threshold)\n",
    "println(\"Good data threshold: \", good_threshold)\n",
    "println(\"Bad data threshold: \", bad_threshold)\n",
    "\n",
    "inverted_reconstruction_error = normalized_reconstruction_error\n",
    "\n",
    "# Calculate adaptive thresholds based on median and standard deviation\n",
    "inverted_median = median(inverted_reconstruction_error)\n",
    "inverted_std = std(inverted_reconstruction_error)\n",
    "\n",
    "bad_threshold = inverted_median + 1.5 * inverted_std\n",
    "\n",
    "# Identify outliers and uncertain points based on adaptive thresholds\n",
    "outliers = findall(inverted_reconstruction_error .> bad_threshold)\n",
    "\n",
    "# Convert indices to dates if necessary\n",
    "outlier_dates = X_date[outliers]\n",
    "\n",
    "# Output results\n",
    "if !isempty(outlier_dates)\n",
    "    println(\"Outliers detected at the following dates:\")\n",
    "    for date in outlier_dates\n",
    "        println(\"    \", Dates.format(date, \"yyyy-mm-dd HH:MM\"))\n",
    "    end\n",
    "else\n",
    "    println(\"No outliers detected.\")\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552e7e8-c575-46fd-b65e-43a4a8034d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0671d7d-cc84-4fb6-a4a9-f8d558be9608",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "start_time = X_date[1]\n",
    "end_time = X_date[end]\n",
    "\n",
    "tm_tick = range(start_time, end_time, step=Hour(2))\n",
    "    ticks = Dates.format.(tm_tick, \"HH\")\n",
    "\n",
    "title=\"Hybrid Model reconstruction errors\"\n",
    "\n",
    "plot( size=(1200,600), dpi=100, title=title, xlims=(start_time,end_time), ylims=(0,Inf), xticks=(tm_tick, ticks), framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "        legend=:bottomleft, xtickfont=font(8), ytickfont=font(8), bottommargin=5Plots.mm, \n",
    "        grid=true, gridlinewidth=0.125, gridstyle=:dot, gridcolor=:grey, gridalpha=0.5)\n",
    "plot!(X_date, inverted_reconstruction_error, lw=:2, lc=:grey, label=\"\")\n",
    "\n",
    "hspan!([bad_threshold, ylims()[2]], fillcolor=:red, fillalpha=:0.125, label=\"Outlier area\")\n",
    "\n",
    "vline!(outlier_dates, ls=:dash, lc=:red, lw=:0.5, label=\"Detected Outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce990895-1115-4acf-8c1e-5f7c9550fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics: quantile\n",
    "using Plots: hspan!\n",
    "\n",
    "\n",
    "function do_plots(ii, start_time, heave)\n",
    "####################################\n",
    "    \n",
    "    end_time = start_time + Minute(30)\n",
    "    xvals = start_time + Microsecond.((0:REC_LENGTH-1) / SAMPLE_FREQUENCY * 1000000)\n",
    "\n",
    "    Q1 = quantile(heave, 0.25)\n",
    "    Q3 = quantile(heave, 0.75)\n",
    "\n",
    "    multiplier = 1.5\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "\n",
    "    # Plot initialization\n",
    "    p1 = plot(size=(2000, 400), dpi=100, framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "        legend=:topright, xtickfont=font(8), ytickfont=font(8), bottommargin=5Plots.mm, \n",
    "        grid=true, gridlinewidth=0.125, gridstyle=:dot, gridcolor=:grey, gridalpha=0.5)\n",
    "    \n",
    "    p1 = hspan!([lower_bound, upper_bound], fillcolor=:lightblue, fillalpha=:0.125, label=\"IQR limits\")\n",
    "    \n",
    "    tm_tick = range(start_time, end_time, step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick, \"MM\")\n",
    "    \n",
    "    # Calculate dynamic confidence interval\n",
    "    confidence_interval = 3.29 # threshold at the 99.9th percentile level\n",
    "\n",
    "    # Identify z_scores using modified z-score\n",
    "    z_score_indices, mod_z_scores = modified_z_score(heave, confidence_interval)\n",
    "    if !isempty(z_score_indices)\n",
    "        scatter!(p1, xvals[z_score_indices], heave[z_score_indices], \n",
    "            markersize=4, markerstrokecolor=:red, markerstrokewidth=1, \n",
    "            markercolor=:white, markershape=:circle, label=\"Modified Z-score beyond 99.9% confidence limits\")\n",
    "    end\n",
    "\n",
    "    # Plot confidence limits\n",
    "    confidence_limits = calc_confidence_limits(heave, confidence_interval)\n",
    "    hline!(p1, [confidence_limits[1], confidence_limits[2]], color=:red, lw=0.5, linestyle=:dash, label=\"99.9% confidence limits\")\n",
    "\n",
    "    # Plot heave data\n",
    "    plot!(p1, xvals, heave, xlims=(xvals[1], xvals[end]), lw=0.5, lc=:blue, alpha=0.5, \n",
    "        xticks=(tm_tick, ticks), label=\"\")\n",
    "\n",
    "    # Annotate plot with the number of outliers and confidence interval\n",
    "    num_outliers = length(z_score_indices)\n",
    "    suspect_string = string(\"  \", string(ii),\" \",Dates.format(start_time, \"yyyy-mm-dd HH:MM\"), \" - \", num_outliers, \" Possible outliers\") # using Confidence Interval of \", \n",
    "##        @sprintf(\"%.2f\", confidence_interval))\n",
    "    annotate!(p1, xvals[1], maximum(heave) * 0.9, text(suspect_string, :left, 10, :blue))\n",
    "\n",
    "    display(p1)\n",
    "    \n",
    "end    # do_plots()  \n",
    "\n",
    "\n",
    "for ii ∈ outliers\n",
    "\n",
    "    # Initialize variables\n",
    "    start_time = X_date[ii]\n",
    "    global heave = X_data[:, ii]\n",
    "    \n",
    "    do_plots(ii, start_time, heave)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86832c4",
   "metadata": {},
   "source": [
    "### Plot records with suspect data (as identified by the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69caf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_plots(ii, start_time, heave)\n",
    "####################################\n",
    "    \n",
    "    end_time = start_time + Minute(30)\n",
    "    xvals = start_time + Microsecond.((0:REC_LENGTH-1) / SAMPLE_FREQUENCY * 1000000)\n",
    "\n",
    "    Q1 = quantile(heave, 0.25)\n",
    "    Q3 = quantile(heave, 0.75)\n",
    "\n",
    "    multiplier = 1.5\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "\n",
    "    # Plot initialization\n",
    "    p1 = plot(size=(2000, 400), dpi=100, framestyle=:box, fg_legend=:transparent, bg_legend=:transparent, \n",
    "        legend=:topright, xtickfont=font(8), ytickfont=font(8), bottommargin=5Plots.mm, \n",
    "        grid=true, gridlinewidth=0.125, gridstyle=:dot, gridcolor=:grey, gridalpha=0.5)\n",
    "    \n",
    "    p1 = hspan!([lower_bound, upper_bound], fillcolor=:lightblue, fillalpha=:0.25, label=\"IQR limits\")\n",
    "    \n",
    "    tm_tick = range(start_time, end_time, step=Minute(1))\n",
    "    ticks = Dates.format.(tm_tick, \"MM\")\n",
    "    \n",
    "    # Calculate dynamic confidence interval\n",
    "    confidence_interval = 3.29 # threshold at the 99.9th percentile level\n",
    "\n",
    "    # Identify z_scores using modified z-score\n",
    "    z_score_indices, mod_z_scores = modified_z_score(heave, confidence_interval)\n",
    "    if !isempty(z_score_indices)\n",
    "        scatter!(p1, xvals[z_score_indices], heave[z_score_indices], \n",
    "            markersize=4, markerstrokecolor=:red, markerstrokewidth=1, \n",
    "            markercolor=:white, markershape=:circle, label=\"Modified Z-score beyond 99.9% confidence limits\")\n",
    "    end\n",
    "\n",
    "    # Plot confidence limits\n",
    "    confidence_limits = calc_confidence_limits(heave, confidence_interval)\n",
    "    hline!(p1, [confidence_limits[1], confidence_limits[2]], color=:red, lw=0.5, linestyle=:dash, label=\"99.9% confidence limits\")\n",
    "\n",
    "    # Plot heave data\n",
    "    plot!(p1, xvals, heave, xlims=(xvals[1], xvals[end]), lw=0.5, lc=:blue, alpha=0.5, \n",
    "        xticks=(tm_tick, ticks), label=\"\")\n",
    "\n",
    "    # Annotate plot with the number of outliers and confidence interval\n",
    "    num_outliers = length(z_score_indices)\n",
    "    suspect_string = string(\"  \", string(ii),\" \",Dates.format(start_time, \"yyyy-mm-dd HH:MM\"), \" - \", num_outliers, \" Possible outliers\") # using Confidence Interval of \", \n",
    "##        @sprintf(\"%.2f\", confidence_interval))\n",
    "    annotate!(p1, xvals[1], maximum(heave) * 0.9, text(suspect_string, :left, 10, :blue))\n",
    "\n",
    "    display(p1)\n",
    "    \n",
    "end    # do_plots()  \n",
    "\n",
    "    \n",
    "for ii ∈ outlier_indices\n",
    "\n",
    "    # Initialize variables\n",
    "    start_time = X_date[ii]\n",
    "    global heave = X_data[:, ii]\n",
    "    \n",
    "    do_plots(ii, start_time, heave)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb9312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
